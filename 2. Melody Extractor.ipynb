{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will process the music files previously created and build the melody descriptors using Melodia.\n",
    "\n",
    "There are three processes here. The first one will take the original music files, the second one will process the  vocals-only, and the third one will take the accompaniments.\n",
    "\n",
    "A final process will take the descriptors created by the last two and concatenate them giving the vocals priority over the accompaniments. This last process was created for future experiments where the full song is present but the vocals, in theory, will be described in a more clear way given that there is no accompaniment sounds. This would help in cases where the user hums both the accompaniment and the lyrics of a song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import essentia.standard\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_melody_files(filename):\n",
    "    with open(filename) as f:\n",
    "        _notes = f.read()\n",
    "\n",
    "    _notes = _notes.split(',')\n",
    "    return [float(i) for i in _notes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dataset/sources/'\n",
    "vocals = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for song in vocals:\n",
    "    loader = essentia.standard.EqloudLoader(filename=path + song, sampleRate=44100)\n",
    "    audio = loader()\n",
    "    pitch_extractor = essentia.standard.PredominantPitchMelodia(frameSize=2048, hopSize=180)\n",
    "    pitch_values, _ = pitch_extractor(audio)\n",
    "\n",
    "    with open('dataset/melodies/full_songs/' + song.split('.')[0] + '.txt', 'w') as writer:\n",
    "        writer.write(','.join(str(e) for e in pitch_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dataset/results/vocals_spleeter/'\n",
    "#path = 'dataset/results/vocals_demucs/'\n",
    "vocals = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vocal in vocals:\n",
    "    loader = essentia.standard.EqloudLoader(filename=path + vocal, sampleRate=44100)\n",
    "    audio = loader()\n",
    "    pitch_extractor = essentia.standard.PredominantPitchMelodia(frameSize=2048, hopSize=180)\n",
    "    pitch_values, _ = pitch_extractor(audio)\n",
    "\n",
    "    with open('dataset/melodies/vocals_spleeter/' + vocal.split('.')[0] + '.txt', 'w') as writer:\n",
    "        writer.write(','.join(str(e) for e in pitch_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dataset/results/accompaniments/'\n",
    "accompaniments = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for accompaniment in accompaniments:\n",
    "    loader = essentia.standard.EqloudLoader(filename=path + accompaniment, sampleRate=44100)\n",
    "    audio = loader()\n",
    "    pitch_extractor = essentia.standard.PredominantPitchMelodia(frameSize=2048, hopSize=50)\n",
    "    pitch_values, _ = pitch_extractor(audio)\n",
    "\n",
    "    with open('dataset/melodies/accompaniments/' + accompaniment.split('.')[0] + '.txt', 'w') as writer:\n",
    "        writer.write(','.join(str(e) for e in pitch_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocals_path = 'dataset/melodies/vocals_spleeter/'\n",
    "#vocals_path = 'dataset/melodies/vocals_demucs/'\n",
    "vocals = os.listdir(vocals_path)\n",
    "accompaniments_path = 'dataset/melodies/accompaniments/'\n",
    "accompaniments = os.listdir(accompaniments_path)\n",
    "results_path = 'dataset/melodies/concatenations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vocal in vocals:\n",
    "    for accompaniment in accompaniments:\n",
    "        if vocal == accompaniment:\n",
    "            vocal_string = read_melody_files(vocals_path + vocal)\n",
    "            accompaniment_string = read_melody_files(accompaniments_path + accompaniment)\n",
    "\n",
    "            result = np.zeros(len(vocal_string))\n",
    "            \n",
    "            for i in range(len(vocal_string)):\n",
    "                if vocal_string[i] != 0:\n",
    "                    result[i] = vocal_string[i]\n",
    "                else:\n",
    "                    if accompaniment_string[i] != 0:\n",
    "                        result[i] = accompaniment_string[i]\n",
    "            \n",
    "            with open(results_path + vocal, 'w') as writer:\n",
    "                writer.write(','.join(str(e) for e in result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
